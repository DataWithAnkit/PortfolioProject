# -*- coding: utf-8 -*-
"""Titanic Survival Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GTB7BuPHB9F82x4rWsXoBZdQqut5LTvP
"""

# Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, precision_recall_curve, auc

# Reading CSV File
data = pd.read_csv('train.csv')

"""Exploratory Data Analysis"""

data.head()

# Bar plot of survival counts
# This graph shows Survival Count; 0 denotes Not Survived, 1 denotes Survived
sns.countplot(x='Survived', data=data)
plt.title('Survival Count')

# Bar plot of passenger class counts
# pclass	denotes Ticket class as following:	1 = 1st, 2 = 2nd, 3 = 3rd
sns.countplot(x='Pclass', data=data)
plt.title('Passenger Class Count')
plt.xlabel('Pclass')
plt.ylabel('Count')
plt.show()

# Bar plot of gender counts
sns.countplot(x='Sex', data=data)
plt.title('Gender Count')

# Histogram of age distribution
sns.histplot(data['Age'].dropna(), kde=True)
plt.title('Age Distribution')
plt.show()

# Swarmplot of age distribution
# It represent the distribution of Age
# It is observed that Age above 70 can be treated as outlier to improve efficiency
sns.swarmplot(x='Age',data=data)
plt.show()

# Violinplot to represent survival by passenger class
# Y-Axis - pclass -	Ticket class:- 1 = 1st, 2 = 2nd, 3 = 3rd
# X-Axis - 0 Not Survived, 1 - Survived
# Not Survived - 3rd class is is more than 1st & 2nd
# Survived - 2nd class are least survived
sns.violinplot(y='Pclass',x='Survived',hue='Sex',data=data)
plt.title('Survival Count by Passenger Class')
plt.xlabel('Survived')
plt.ylabel('Count')
plt.legend(title='Sex')
plt.show()

sns.violinplot(y='Pclass',x='Survived',hue='Sex',data=data,split=True)
plt.show()

# Bar plot of survival counts by gender
# Not Survived - male are higher than female
# Survived - female are higher than male
sns.countplot(x='Survived', hue='Sex', data=data)
plt.title('Survival Count by Gender')
plt.xlabel('Survived')
plt.ylabel('Count')
plt.legend(title='Sex')
plt.show()

# Box plot of fare distribution for each passenger class
sns.boxplot(x='Pclass', y='Fare', data=data)
plt.title('Fare Distribution by Passenger Class')
plt.xlabel('Pclass')
plt.ylabel('Fare')
plt.show()

# KDE plot of age distribution for survived and not survived passengers
sns.kdeplot(data[data['Survived'] == 0]['Age'].dropna(), label='Not Survived', fill=True)
sns.kdeplot(data[data['Survived'] == 1]['Age'].dropna(), label='Survived', fill=True)
plt.title('Age Distribution by Survival')
plt.xlabel('Age')
plt.ylabel('Density')
plt.legend()
plt.show()

# Pearson correlation heatmap
# The resulting heatmap represents the pairwise correlations between the numeric variables in the dataset.
# Each cell in the heatmap represents the correlation between two variables,
# with values ranging from -1 to 1.
# The color intensity of each cell indicates the strength and direction of the correlation.
correlation = data.corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm')
plt.title('Pearson Correlation Heatmap')
plt.show()

"""This plot is useful for identifying relationships and dependencies between variables. Strong positive correlations are shown in red, indicating variables that tend to increase or decrease together, while strong negative correlations are shown in blue, indicating variables that tend to have an inverse relationship. The heatmap helps in understanding the interrelationships and potential multicollinearity among the variables, which can be valuable for feature selection and understanding the impact of variables on the target variable.

Data Preprocessing
"""

# Drop irrelevant columns
data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)

data.head()

# Split features and target variable
X = data.drop('Survived', axis=1)
Y = data['Survived']

# Creating list of new features
X['FamilySize'] = X['SibSp'] + X['Parch']
X['IsAlone'] = np.where(X['FamilySize'] > 0, 0, 1)

X.head()

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Define numeric and categorical features
numeric_features = ['Age', 'Fare']
categorical_features = ['Sex', 'Pclass']

# Create preprocessing pipeline
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder())
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
])

# Apply preprocessing
X_train_preprocessed = preprocessor.fit_transform(X_train)
X_test_preprocessed = preprocessor.transform(X_test)

"""Cross Validation"""

# Define the classifier
classifier = RandomForestClassifier(random_state=42)

# Perform cross-validation
cv_scores = cross_val_score(classifier, X_train_preprocessed, Y_train, cv=5, scoring='roc_auc')
print('Cross-Validation Scores:', cv_scores)
print('Average ROC AUC:', np.mean(cv_scores))

"""Model Evaluation and Metrics"""

# Fit the classifier
classifier.fit(X_train_preprocessed, Y_train)

# Predict probabilities and calculate metrics
Y_pred_probability = classifier.predict_proba(X_test_preprocessed)[:, 1]
fpr, tpr, _ = roc_curve(Y_test, Y_pred_probability)
precision, recall, _ = precision_recall_curve(Y_test, Y_pred_probability)
roc_auc = auc(fpr, tpr)
pr_auc = auc(recall, precision)

# Plot ROC curve
plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()

# Plot Precision-Recall curve
plt.plot(recall, precision, label='Precision-Recall curve (AUC = %0.2f)' % pr_auc)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='lower left')
plt.show()

"""Inference Pipeline"""



# Create the inference pipeline
inference_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', classifier)
])
inference_pipeline

# Fit the inference pipeline on the entire dataset
inference_pipeline.fit(X, Y)

inference_pipeline.score(X, Y)

# Function to predict survival using the inference pipeline
def predict_survival(passenger_data):
    passenger_data = pd.DataFrame(passenger_data).T
    passenger_data.columns = X.columns
    prediction = inference_pipeline.predict(passenger_data)
    return prediction

# Load the test data from the "test.csv" file
test_data = pd.read_csv("test.csv")
test_data.head()

# Use the inference pipeline to make predictions for the test data
predictions = inference_pipeline.predict(test_data)

# Add the predictions to the test data as a new column
test_data['Survived'] = predictions
test_data.head()

# Save the test data with predictions to a new CSV file
test_data.to_csv("test_predictions.csv", index=False)